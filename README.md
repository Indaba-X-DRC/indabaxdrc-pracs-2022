# indabaxdrc-pracs-2022
Praticals Notebooks for the Indaba X DRC 2022.
## The Practicals 
| Topic üí• | Description üìò |
|:--- |----------------------------------------------------------|
[Deep Computer Vision Tutorial](https://github.com/Indaba-X-DRC/indabaxdrc-pracs-2022/blob/main/practicals/Deep_Computer_Vision_tutorial.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Indaba-X-DRC/indabaxdrc-pracs-2022/blob/main/practicals/Deep_Computer_Vision_tutorial.ipynb) | In this tutorial, we will explore where Convolutional neural networks (CNNs) came from, what their building blocks look like, and how to implement them using TensorFlow and Keras. Then we will discuss some of the best CNN architectures, as well as other visual tasks, including object detection (classifying multiple objects in an image and placing bounding boxes around them) and semantic segmentation (classifying each pixel according to the class of the object it belongs to).  | 
[End-to-End Machine Learning Intro](https://github.com/Indaba-X-DRC/indabaxdrc-pracs-2022/blob/main/practicals/End_to_end_Machine_Learning_Intro.ipynb) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Indaba-X-DRC/indabaxdrc-pracs-2022/blob/main/practicals/End_to_end_Machine_Learning_Intro.ipynb) | In this chapter you will work through an example project end to end, pretending to be a recently hired data scientist at a real estate company. Here are the main steps you will go through:<br />1. Look at the big picture.<br />2. Get the data.<br />3. Discover and visualize the data to gain insights.<br />4. Prepare the data for Machine Learning algorithms.<br />5. Select a model and train it.<br />6. Fine-tune your model.<br />7. Present your solution.<br />8. Launch, monitor, and maintain your system.| 
[Introduction to Artificial Neural Networks with Keras](https://github.com/Indaba-X-DRC/indabaxdrc-pracs-2022) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/Indaba-X-DRC/indabaxdrc-pracs-2022) | The transformer architecture, introduced in Vaswani et al. 2017's paper [Attention is All You Need](https://arxiv.org/abs/1706.03762?amp=1), has significantly impacted the deep learning field. It has arguably become the de-facto architecture for complex Natural Language Processing (NLP) tasks. It can also be applied in various domains reaching state-of-the-art performance, including computer vision and reinforcement learning. Transformers, as the title of the original paper implies, are almost entirely based on a concept known as attention. Attention allows models to "focus" on different parts of an input; while considering the entire context of the input versus an RNN, that operates on the data sequentially. In this practical, we will introduce attention in greater detail and build the entire transformer architecture block by block to see why it is such a robust and powerful architecture | 
[Unsupervised Learning Techniques](https://github.com/Indaba-X-DRC/indabaxdrc-pracs-2022) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/Indaba-X-DRC/indabaxdrc-pracs-2022) | we looked at the most common unsupervised learning task: dimensionality reduction. In this tutorial we will look at a few more unsupervised learning tasks and algorithms:<br />Clustering<br />The goal is to group similar instances together into clusters. Clustering is a great tool for data analysis, customer segmentation, recommender systems, search engines, image segmentation, semi-supervised learning, dimensionality reduction, and more.<br />Anomaly detection<br />The objective is to learn what ‚Äúnormal‚Äù data looks like, and then use that to detect abnormal instances, such as defective items on a production line or a new trend in a time series.<br />Density estimation<br />This is the task of estimating the probability density function (PDF) of the random process that generated the dataset. Density estimation is commonly used for anomaly detection: instances located in very low-density regions are likely to be anomalies. It is also useful for data analysis and visualization. | 
[Support Vector Machines](https://github.com/Indaba-X-DRC/indabaxdrc-pracs-2022) <br /> <br /> [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/Indaba-X-DRC/indabaxdrc-pracs-2022) | In this practical, we will explain the core concepts of SVMs, how to use them, and how they work. |


This repository contains the practical notebooks for the IndabaX DRC
2022, held at MAPOND University in Kindu, Maniema D.R. Congo.

See [www.indabax-drc.com](http://www.indabax-drc.com) for more details.
